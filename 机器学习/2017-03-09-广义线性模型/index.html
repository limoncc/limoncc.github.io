<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,广义线性模型," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="本文意在理清广义线性模型的问题。若有错误，请大家指正。">
<meta name="keywords" content="机器学习,广义线性模型">
<meta property="og:type" content="article">
<meta property="og:title" content="广义线性模型">
<meta property="og:url" content="http://www.limoncc.com/机器学习/2017-03-09-广义线性模型/index.html">
<meta property="og:site_name" content="柠檬CC">
<meta property="og:description" content="本文意在理清广义线性模型的问题。若有错误，请大家指正。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://www.limoncc.com/图片/广义线性模型.png">
<meta property="og:image" content="http://www.limoncc.com/images/cc.png">
<meta property="og:image" content="http://www.limoncc.com/images/avatar.png">
<meta property="og:updated_time" content="2021-11-09T13:18:20.454Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="广义线性模型">
<meta name="twitter:description" content="本文意在理清广义线性模型的问题。若有错误，请大家指正。">
<meta name="twitter:image" content="http://www.limoncc.com/图片/广义线性模型.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: undefined,
      author: '博主'
    }
  };
</script>

  <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
  <title> 广义线性模型 | 柠檬CC </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-73837972-3', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?d225b8f8559eb2eb6a8bd8792e01ebb9";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  <script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=60130136";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">柠檬CC</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">小白爱吃柠檬O(∩_∩)O</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-poetry">
          <a href="/poetry" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-leaf"></i> <br />
            
            诗集
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                广义线性模型
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-09T20:36:43+08:00" content="2017-03-09">
              2017-03-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/机器学习/2017-03-09-广义线性模型/" class="leancloud_visitors" data-flag-title="广义线性模型">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>作者: <a href="http://www.limoncc.com">引线小白</a>-本文永久链接：<a href="http://www.limoncc.com/机器学习/2017-03-09-广义线性模型/">http://www.limoncc.com/机器学习/2017-03-09-广义线性模型/</a><br>知识共享许可协议: 本博客采用<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="external">署名-非商业-禁止演绎4.0</a>国际许可证</p>
<blockquote>
<p><strong>摘要</strong>：本文意在理清广义线性模型的问题。若有错误，请大家指正。<br><strong>关键词</strong>: <code>广义线性模型</code>,<code>广义线性混合模型</code>,<code>指数族</code>,<code>probit 回归</code></p>
</blockquote>
<h4 id="一、-简述"><a href="#一、-简述" class="headerlink" title="一、 简述"></a>一、 简述</h4><p>我们现在遇到了各种各样的概率分布：高斯分布、伯努利分布、学生 $\displaystyle  \text{t}$分布、均匀分布、伽玛分布等等，这些都是广义分布的广义函数，称为指数族。在本章中，我们将讨论这个家族的各种性质。这使我们能够得到具有非常广泛适用性的定理和算法。</p>
<p>我们将会看到，如何方便地将指数家族中的任何成员作为一个类条件密度，以便做一个生成分类器。此外，我们还将讨论如何建立判别模型，其中的响应变量有指数族分布，其均值是输入的线性函数；这被称为广义线性模型，并将 $\displaystyle \textit{logistic } $回归中的概念推广到其他类型的响应变量中。</p>
<h4 id="二、-指数族"><a href="#二、-指数族" class="headerlink" title="二、 指数族"></a>二、 指数族</h4><p>在定义指数族之前，我们先提几个重要原因:</p>
<p>•可以证明，在一定的规律性条件下，指数族是唯一具有有限大小统计量的分布族，这意味着我们可以将数据压缩成一个固定大小的摘要，而不会丢失信息。这对于在线学习特别有用，我们稍后会看到。</p>
<p>•指数族是有共轭先验分布存在的唯一分布族，这简化了后验计算。</p>
<p>•在满足一些约束的假设下，指数族是熵最大的一个分布家族。</p>
<p>•指数族是广义线性模型的核心。</p>
<p>•指数族是变分推断的核心。</p>
<h5 id="2-1、定义"><a href="#2-1、定义" class="headerlink" title="2.1、定义"></a>2.1、定义</h5><p>参数为 $\displaystyle \bm{w} $，变量为 $\displaystyle \bm{x} $ 的指数分布族定义为下面形式的概率分布集合：<br>$$<br>\begin{align}<br>p(\bm{x}\mid \bm{w})<br>&amp;=\frac{1}{Z(\bm{w})}h(\bm{x})\exp\left[\bm{w}^\text{T}\bm{T}(\bm{x})\right]<br>=h(\bm{x})\exp\big[\bm{w}^\text{T}\bm{T}(\bm{x})-A(\bm{w})\big]\<br>\end{align}<br>$$<br>特别的为了适合上述形式，参数通常是需要变形 $\displaystyle \bm{\eta}=\bm{\eta}(\bm{w})$，于是有：<br>$$\begin{align}<br>p(\bm{x}\mid \bm{w})<br>&amp;=\frac{1}{Z(\bm{w})}h(\bm{x})\exp\left[\bm{\eta}(\bm{w})^\text{T}\bm{T}(\bm{x})\right]\\\\<br>&amp;=h(\bm{x})\exp\left[\bm{\eta}(\bm{w})^\text{T}\bm{T}(\bm{x})-A(\bm{\eta}(\bm{w}))\right]\\\\<br>&amp;=\exp\left[\bm{\eta}(\bm{w})^\text{T}\bm{T}(\bm{x})-A\left(\bm{\eta}(\bm{w})\right)+B(\bm{x})\right]\\\\<br>&amp;=h(\bm{x})g(\bm{\eta})\exp\left[\bm{\eta}(\bm{w})\cdot\bm{T}(\bm{x})\right]<br>\end{align}$$其中：<br>$\displaystyle Z(\bm{w})=\int_{\mathcal{X}^n}h(\bm{x})\exp\left[\bm{\eta^\text{T}(\bm{w})}\bm{T}(\bm{x})\right]\mathrm{d}\bm{x}$</p>
<p>$\displaystyle A(\bm{w})=\ln Z(\bm{w}) $<br>1、$\displaystyle \bm{w} $叫做自然参数 $\displaystyle \textit{(natural parameters)} $、$\displaystyle \bm{\eta(\bm{w})} $叫做规范参数 $\displaystyle \textit{(canonical parameters)} $ 。如果 $\displaystyle \dim(\bm{w})&lt;\dim(\bm{\eta}) $，称分布为曲线指数族 $\displaystyle \textit{(curved exponential family)} $。这意味比参数更多的充分统计量。</p>
<p>2、 $\displaystyle \bm{T}(\bm{x})\in\mathbb{R}^k $叫做充分统计向量 $\displaystyle \textit{(vector of sufficient statistics)} $。</p>
<p>3、$\displaystyle Z(\bm{w}) $叫做配分函数 $\displaystyle \textit{(partition function)} $</p>
<p>4、$\displaystyle A(\bm{w}) $叫做对数配分函数 $\displaystyle \textit{(log partition function)} $或者累积量函数 $\displaystyle \textit{(cumulant function)} $</p>
<p>5、$\displaystyle  h(\bm{x})  $叫做放缩常量 $\displaystyle \textit{(scaling constant)} $，通常是1。</p>
<p>6、特别的 $\displaystyle \bm{T}(\bm{x})=\bm{x}  $ 称为自然指数族 $\displaystyle \textit{(natural exponential family)} $或者规范形 $\displaystyle \textit{(canonical form)} $</p>
<h5 id="2-2、对数配分函数"><a href="#2-2、对数配分函数" class="headerlink" title="2.2、对数配分函数"></a>2.2、对数配分函数</h5><p>指数族的一个重要性质是对数配分函数的导数可以用来生成充分统计量的累积量。所以 $\displaystyle A \big(\bm{\eta}\big)$有时被称为累积量函数。<br>$$\begin{align}<br>A(\bm{\eta})=\ln \bigg[\int h(\bm{x})\exp \big[\bm{\eta}^\text{T}\bm{T}(\bm{x})\big]d \bm{x}\bigg]<br>\end{align}$$<br>于是有<br>$$\begin{align}<br>\dot{A}(\bm{\eta})=\frac{\partial A}{\partial  \bm{\eta}}<br>&amp;=\frac{\displaystyle\frac{\partial }{\partial  \bm{\eta}}\bigg[\int h(\bm{x})\exp \big[\bm{\eta}^\text{T}\bm{T}(\bm{x})\big]d \bm{x}\bigg]}{\displaystyle\int h(\bm{x})\exp \big[\bm{\eta}^\text{T}\bm{T}(\bm{x})\big]d \bm{x}}<br>=\frac{\displaystyle \int h(\bm{x})\exp \big[\bm{\eta}^\text{T}\bm{T}(\bm{x})\big]\bm{T}d \bm{x}}{\exp \big[A(\bm{\eta})\big]}\\\\<br>&amp;=\int \bm{T} \cdot h(\bm{x})\exp \big[\bm{\eta}^\text{T}\bm{T}(\bm{x})-A(\bm{\eta})\big]d \bm{x}\\\\<br>&amp;=\int \bm{T} \cdot p \big(\bm{x}\big)d \bm{x}<br>=\mathrm{E}\big[\bm{T}(\bm{x})\big]<br>\end{align}$$<br>还有：<br>$$\begin{align}<br>\ddot{A}(\bm{\eta})=\frac{\partial^2 A}{\partial  \bm{\eta}\partial\bm{\eta}^\text{T}}<br>&amp;=\frac{\partial }{\partial  \bm{\eta}^\text{T}}\bigg[\int \bm{T} \cdot h(\bm{x})\exp \big[\bm{\eta}^\text{T}\cdot\bm{T}-A(\bm{\eta})\big]d \bm{x}\bigg]\\\\<br>&amp;=\int \bm{T}^\text{T}\cdot h(\bm{x})\exp \big[\bm{\eta}^\text{T}\cdot\bm{T}-A(\bm{\eta})\big]\big[\bm{T}-\dot{A}(\bm{\eta})\big]d \bm{x}\\\\<br>&amp;=\int \bm{T}^\text{T}\big[\bm{T}-\dot{A}(\bm{\eta})\big]p (\bm{x})d \bm{x}\\\\<br>&amp;=\mathrm{E}\big[\bm{T}^\text{T}\bm{T}\big]- \mathrm{E}\big[\bm{T}^\text{T}\big]\mathrm{E}\big[\mathrm{E}\big[\bm{T}\big]\big]<br>=\mathrm{E}\big[\bm{T}^\text{T}\bm{T}\big]-\mathrm{E}^\text{T}\big[\bm{T}\big]\mathrm{E}\big[\bm{T}\big]\\\\<br>&amp;=\mathrm{cov}\big[\bm{T}(\bm{x})\big]<br>\end{align}$$<br>也就是说<br>$$\begin{align}<br>\nabla^2A \big(\bm{\eta}\big)=\mathrm{cov}\big[\bm{T}(\bm{x})\big]<br>\end{align}$$</p>
<p>由于协方差是正定的，我们看到一个 $\displaystyle A \big(\bm{\eta}\big)$是一个凸函数(参见7.3.3)。注意上面的推导交换了积分和求导顺序，这需要满足一致收敛条件。这显然是满足的。</p>
<h5 id="2-3、例子"><a href="#2-3、例子" class="headerlink" title="2.3、例子"></a>2.3、例子</h5><p>让我们考虑一些例子来让事情更清楚些。</p>
<h6 id="2-3-1、-displaystyle-textit-0-1-分布"><a href="#2-3-1、-displaystyle-textit-0-1-分布" class="headerlink" title="2.3.1、 $\displaystyle \textit{0-1}$分布"></a>2.3.1、 $\displaystyle \textit{0-1}$分布</h6><p>有 $\displaystyle x\in\{0,1\}$的 $\displaystyle \textit{0-1}$分布写成指数族形式：<br>$$\begin{align}<br>\mathrm{Ber}\big(x\mid \mu\big)=\mu^x(1-\mu)^{1-x}=\exp \big[x\ln \mu+(1-x)\ln (1-\mu)\big]=\exp \big[\bm{\eta}^\text{T}\bm{T}(x)\big]<br>\end{align}$$</p>
<p>其中：<br>$\displaystyle \bm{\eta}=\big[\ln \mu,\ln (1-\mu)\big]^\text{T}$<br>$\displaystyle  \bm{T}(x) =\big[\mathbb{I}\big(x=0\big),\mathbb{I}\big(x=1\big)\big]^\text{T}<br>$<br>然后这个表示是过于完备以至于很啰嗦，因为特征之间有线性关系，这很不简洁。<br>$$\begin{align}<br>\bm{I}^\text{T}\bm{T}(x)=\mathbb{I}\big(x=0\big)+\mathbb{I}\big(x=1\big)=1<br>\end{align}$$</p>
<p>因为 $\displaystyle \bm{\eta}$不是唯一的，这要求我们 $\displaystyle  \bm{\eta}$最好是最简洁的。也就是说分布均值和唯一的 $\displaystyle \bm{\eta}$联系。这样我们可以定义：<br>$$\begin{align}<br>\mathrm{Ber}\big(x\mid \mu\big)=(1-\mu)\exp \bigg[x\ln \bigg(\frac{\mu}{1-\mu}\bigg)\bigg]<br>\end{align}$$<br>现在 $\displaystyle \eta=\ln \bigg(\frac{\mu}{1-\mu}\bigg)$这是 $\displaystyle \textit{log-odds ratio} $，$\displaystyle T(x)=x$， $\displaystyle Z=1/(1-\mu)$。于是有：<br>$$\begin{align}<br>A(\eta)=\ln Z=\ln \bigg(\frac{1}{1-\mu}\bigg)=\ln \big[1+\mathrm{e}^\eta\big]<br>\end{align}$$<br>来自规范参数的均值 $\displaystyle \mu$<br>$$\begin{align}<br>\mu=\dot{A}(\eta)=\mathrm{sigm}\big(\eta\big)=\frac{1}{1+\mathrm{e}^{-\eta}}=\eta^{-1}(\mu)<br>\end{align}$$</p>
<h6 id="2-3-2-、分类分布"><a href="#2-3-2-、分类分布" class="headerlink" title="2.3.2 、分类分布"></a>2.3.2 、分类分布</h6><p>令 $\displaystyle x_i=\mathbb{I}(x=i)$，分类分布指数族形式是：<br>$$\begin{align}<br>\mathrm{Cat}\big(\bm{x}\mid \bm{\mu}\big)<br>&amp;=\prod_{i=1}^c\mu_i^{x_i}=\exp \Bigg[\sum_{i=1}^cx_i\ln \mu_i\Bigg]\\\\<br>&amp;=\exp \Bigg[\sum_{i=1}^{c-1}x_i\ln \mu_i+\bigg(1-\sum_{j=1}^{c-1}x_j\bigg)\ln \bigg(1-\sum_{j=1}^{c-1}\mu_j\bigg)\Bigg]\\\\<br>&amp;=\exp \Bigg[\sum_{i=1}^{c-1}x_i\ln \bigg(\frac{\mu_i}{1-\sum_{j=1}^{c-1}\mu_j}\bigg)+\ln\bigg(1-\sum_{j=1}^{c-1}\mu_j\bigg)\Bigg]\\\\<br>&amp;=\exp\Bigg[\sum_{i=1}^{c-1}x_i\ln \bigg(\frac{\mu_i}{\mu_c}\bigg)+\ln \mu_c\Bigg]<br>\end{align}$$ 其中 $\displaystyle \mu_c=1-\sum_{j=1}^{c-1}\mu_j$，有：<br>$$\begin{align}<br>\mathrm{Cat}\big(\bm{x}\mid \bm{\mu}\big)<br>&amp;=\exp \big[\bm{\eta}^\text{T}\bm{T}\big(\bm{x}\big)-A \big(\bm{w}\big)\big]<br>\end{align}$$</p>
<p>其中<br>$\displaystyle \bm{\eta}=\big[\ln \frac{\mu_1}{\mu_c},\cdots,\ln \frac{\mu_{c-1}}{\mu_c}\big]^\text{T}$<br>$\displaystyle \bm{T}\big(\bm{x}\big)=\bm{x}=\big[\mathbb{I}(x=1),\cdots,\mathbb{I}(x=c-1)\big]^\text{T}$<br>同样，我们可以通过使用的规范参数来恢复均值参数<br>$$\begin{align}<br>\mu_i=\frac{\mathrm{e}^{\eta_i}}{1+\sum_{j=1}^{c-1}\mathrm{e}^{\eta_j}}<br>\end{align}$$易知：$$\begin{align}<br>\mu_c<br>=1-\frac{\sum_{i=1}^{c-1}\mathrm{e}^{\eta_i}}{1+\sum_{j=1}^{c-1}\mathrm{e}^{\eta_j}}<br>=\frac{1}{1+\sum_{j=1}^{c-1}\mathrm{e}^{\eta_j}}<br>\end{align}$$亦有$$\begin{align}<br>A \big(\bm{\eta}\big)=\ln \bigg(1+\sum_{i=1}^{c-1}\mathrm{e}^{\eta_i}\bigg)<br>\end{align}$$如果我们定义 $\displaystyle \eta_c=0\to \mu_{i=c}=0$，那么有 $\displaystyle \bm{\eta}:=\big[\bm{\eta}^\text{T},0\big]^\text{T}$， $\displaystyle \bm{T}:=\big[\bm{T}^\text{T},\mathbb{I}\big(x=c\big)\big]^\text{T}$<br>$$\begin{align}<br>\mathrm{Cat}\big(\bm{x}\mid \bm{\mu}\big)<br>&amp;=\exp \big[\bm{\bm{\eta}^\text{T}T}\big(\bm{x}\big)-A \big(\bm{\eta}\big)\big]<br>\end{align}$$其中 $\displaystyle A \big(\bm{\eta}\big)=\ln \bigg(\sum_{i=1}^{c}\mathrm{e}^{\eta_i}\bigg)\\\\$，特别的有：$$\begin{align}<br>\bm{\mu}&amp;=\mathcal{S}\big(\bm{\eta}\big)=\bm{\eta}^{-1}\big(\bm{\mu}\big)<br>\end{align}$$</p>
<p>这样我们就通过指数族建立了 $\displaystyle \textit{sigm}$ 函数与 $\displaystyle \textit{0-1} $分布、 $\displaystyle \textit{softmax} $函数与分类分布的联系。换句话说 $\displaystyle \textit{sigm} $ 函数、 $\displaystyle \textit{softmax} $ 函数是连接函数的逆函数。这也是sigm和sofmax函数在机器学习，人工智能广泛应用的原因，因为只要分类问题，就必然涉及。</p>
<h6 id="2-3-3、单变量高斯"><a href="#2-3-3、单变量高斯" class="headerlink" title="2.3.3、单变量高斯"></a>2.3.3、单变量高斯</h6><p>单变量高斯可以写成指数族形式，如下:</p>
<p>$$\begin{align}<br>\mathcal{N}\big(x\mid \mu,\sigma^2\big)<br>&amp;=\big(2\pi\sigma^2\big)^{-1/2}\exp \big[\frac{1}{2\sigma^2}\big(x-\mu\big)^2\big]\\\\<br>&amp;=\big(2\pi\sigma^2\big)^{-1/2}\exp \big[\frac{\mu^2}{2\sigma^2}\big]\exp \big[-\frac{1}{2\sigma^2}x^2+\frac{\mu}{\sigma^2}x\big]\\\\<br>&amp;=\frac{1}{Z \big(\bm{\eta}\big)}\exp \big[\bm{\eta}^\text{T}\bm{T}(x)\big]<br>\end{align}$$</p>
<p>其中:<br>$\displaystyle \bm{\eta}=\big[\frac{\mu}{\sigma^2},-\frac{1}{2\sigma^2}\big]^\text{T}$<br>$\displaystyle \bm{T}(x)=\big[x,x^2\big]^\text{T}$<br>$\displaystyle  Z \big(\bm{\eta}\big)=\big(2\pi\sigma^2\big)^{-1/2}\exp \big[\frac{\mu^2}{2\sigma^2}\big] $<br>$\displaystyle A \big(\bm{\eta}\big)=\ln Z \big(\bm{\eta}\big)=-\frac{\eta_1^2}{4\eta_2}-\frac{1}{2}\ln \big(-2\eta_2\big)-\frac{1}{2}\ln 2\pi$</p>
<h6 id="2-2-4、非例子"><a href="#2-2-4、非例子" class="headerlink" title="2.2.4、非例子"></a>2.2.4、非例子</h6><p>并非所有的分布都属于指数族。例如均匀分布 $\displaystyle x\sim \mathrm{U}[a,b]$ 就不是，因为分布支撑集 $\displaystyle \mathcal{X}$取决于参数。此外学生 $\displaystyle T$分布也不属于，因为它没有必要的形式。$\displaystyle \textit{Pitman - Koopman - Darmois} $定理指出，在一定规范条件下，指数家族是唯一具有有限统计量的分布族。(在这里，大小有限与数据集的大小无关。)这个定理要求的条件之一是，分布支撑集 $\displaystyle \mathcal{X}$不依赖于参数。对于这样分布的简单示例：均匀分布<br>$$\begin{align}<br>p(x\mid w)=\mathrm{U}(x\mid w)=\frac{\mathbb{I}\big(0\leqslant x\leqslant w\big)}{w}<br>\end{align}$$<br>似然函数是：<br>$$\begin{align}<br>p \big(\mathcal{D}\big)=w^{-n}\mathbb{I}\big(0\leqslant\max\{x_i\}\leqslant w\big)<br>\end{align}$$</p>
<p>因此充分统计量是 $\displaystyle n$和 $\displaystyle T=\max_{i}x_i$。它是有限的，但均匀分布并不在指数家族中。因为它的支撑集 $\displaystyle \mathcal{X}=[0,w]$ 依赖于参数 $\displaystyle w$。</p>
<h5 id="2-4、指数族的-displaystyle-textit-MLE"><a href="#2-4、指数族的-displaystyle-textit-MLE" class="headerlink" title="2.4、指数族的 $\displaystyle  \textit{MLE}$"></a>2.4、指数族的 $\displaystyle  \textit{MLE}$</h5><p>指数家族模型似然函数：<br>$$\begin{align}<br>p \big(\mathcal{D}\mid \bm{w}\big)<br>&amp;=\frac{1}{Z^n(\bm{w})}\bigg[\prod_{i=1}^n h(\bm{x}_i)\bigg]\exp \bigg[\bm{\eta}^\text{T}(\bm{w})\sum_{i=1}^n \bm{T}(\bm{x}_i)\bigg]\\\\<br>&amp;=\bigg[\prod_{i=1}^n h(\bm{x}_i)\bigg]\exp \bigg[\bm{\eta}^\text{T}(\bm{w})\bm{T}(\mathcal{D})-nA \big(\bm{\eta}\big)\bigg]<br>\end{align}$$</p>
<p>易见似然函数也是指数族，它的充分统计量是 $\displaystyle n$和<br>$$\begin{align}<br>\bm{T}\big(\mathcal{D}\big)=\bigg[\sum_{i=1}^n T_1(\bm{x}_i),\cdots,\sum_{i=1}^nT_k(\bm{x}_i)\bigg]^\text{T}<br>\end{align}$$</p>
<p>例如伯努利分布我们有 $\displaystyle \bm{T}=\bigg[\sum_{i=1}^n \mathbb{I}(\bm{x}_i)\bigg]$和单变量高斯分布 $\displaystyle \bm{T}=\big[\sum_{i=1}^nx_i,\sum_{i=1}^nx_i^2\big]$(我们也需要知道样本大小 $\displaystyle n$)</p>
<p>现在我们给定 $\displaystyle \mathrm{idd}$数据集 $\displaystyle \mathcal{D}=\{\bm{x}_i\}_{i=1}^n$，用标准指数家族模型来计算 $\displaystyle \textit{MLE} $。对数似然函数：<br>$$\begin{align}<br>\ell(\bm{\eta})=\ln p \big(\mathcal{D}\mid \bm{\eta}\big)<br>=\bigg[\sum_{i=1}^n\ln h(\bm{x}_i)\bigg]+\bigg[\bm{\eta}^\text{T}(\bm{w})\bm{T}(\mathcal{D})-nA \big(\bm{\eta}\big)\bigg]<br>\end{align}$$</p>
<p>因为 $\displaystyle  -A \big(\bm{\eta}\big)$关于 $\displaystyle \bm{\eta}$是凹的， $\displaystyle \bm{\eta}^\text{T}(\bm{w})\bm{T}(\mathcal{D})$关于 $\displaystyle \bm{\eta}$是线性的。故对数似然是凹的，因此有唯一的全局最大值。为了得到这个最大值，利用关于对数分配函数导数是充分统计量期望的结论有：<br>$$\begin{align}<br>\frac{\partial \ell}{\partial \bm{\eta}}=\bm{T}(\mathcal{D})-n \mathrm{E}\big[\bm{T}(\bm{x})\big]=\bm{0}<br>\end{align}$$有：$$\begin{align}<br>\mathrm{E}\big[\bm{T}(\bm{x})\big]=\frac{1}{n}\bm{T}\big(\mathcal{D}\big)<br>\end{align}$$</p>
<p>充分统计量的经验平均值必须等于模型充分统计量的理论期望，即 $\displaystyle \hat{\bm{\eta}}$必须满足上式。这叫做时刻匹配 $\displaystyle \textit{(moment matching)} $。例如在伯努利分布中，我们有 $\displaystyle T(\mathcal{D})=\sum_{i=1}^n \mathbb{I}\big(x_i=1\big)$有：<br>$$\begin{align}<br>\mathrm{E}\big[\bm{T}(\bm{x})\big]=\hat{\mu}=\frac{1}{n}\sum_{i=1}^n \mathbb{I}\big(x_i=1\big)<br>\end{align}$$</p>
<h5 id="2-5、指数族的贝叶斯"><a href="#2-5、指数族的贝叶斯" class="headerlink" title="2.5、指数族的贝叶斯"></a>2.5、指数族的贝叶斯</h5><p>我们已经看到，如果先验概率是共轭的，那么精确贝叶斯分析是相当简单的。非正式这意味着先验 $\displaystyle p \big(\bm{\eta}\mid \bm{\tau}\big)$与似然函数 $\displaystyle p \big(\mathcal{D}\mid \bm{\eta}\big)$有相同形式。为了这个有意义，我们要求似然函数的充分统计量是有限，所以我们可以写 $\displaystyle p \big(\mathcal{D}\mid \bm{\eta}\big)=p \big(\bm{T}(\mathcal{D})\mid \bm{\eta}\big)$。这表明，唯一有共轭先验的分布族是指数族。稍后我们将推导先验和后验。</p>
<h6 id="2-5-1、似然函数"><a href="#2-5-1、似然函数" class="headerlink" title="2.5.1、似然函数"></a>2.5.1、似然函数</h6><p>我们多角度地写出指数族似然函数：<br>$$\begin{align}<br>p \big(\mathcal{D}\mid \bm{w}\big)<br>&amp;=\frac{1}{Z^n(\bm{w})}\bigg[\prod_{i=1}^n h(\bm{x}_i)\bigg]\exp \bigg[\bm{\eta}^\text{T}(\bm{w})\bm{T}(\mathcal{D})\bigg]\\\\<br>&amp;\propto\exp \bigg[\bm{\eta}^\text{T}(\bm{w})\bm{T}(\mathcal{D})-nA \big(\bm{\eta}\big)\bigg]\\\\<br>&amp;\propto\exp \bigg[n\bm{\eta}^\text{T}\bar{\bm{T}}-nA \big(\bm{\eta}\big)\bigg]<br>\end{align}$$</p>
<p>其中 $\displaystyle \bar{\bm{T}}=\frac{1}{n}\bm{T}(\mathcal{D})$</p>
<h6 id="2-5-2、先验"><a href="#2-5-2、先验" class="headerlink" title="2.5.2、先验"></a>2.5.2、先验</h6><p>共轭先验有如下形式：<br>$$\begin{align}<br>p \big(\bm{\eta}\mid \kappa_0,\bm{\tau}_0\big)<br>\propto g^{\kappa_0}(\bm{\eta})\exp \big[\bm{\eta}^\text{T}(\bm{w})\bm{\tau}_0\big]<br>\end{align}$$</p>
<p>令 $\displaystyle \bm{\tau}=\kappa_0\bar{\bm{\tau}}_0$，这样我们分离出先验的虚数据集大小 $\displaystyle \kappa_0$，和虚数据集充分统计量均值 $\displaystyle \bar{\bm{\tau}}_0$。在规范形式中，先验成为：<br>$$\begin{align}<br>p \big(\bm{\eta}\mid \kappa_0,\bar{\bm{\tau}}_0\big)<br>\propto \exp \big[\kappa_0\bm{\eta}^\text{T}\bar{\bm{\tau}}_0-\kappa_0A(\bm{\eta})\big]<br>\end{align}$$</p>
<h6 id="2-5-3、后验"><a href="#2-5-3、后验" class="headerlink" title="2.5.3、后验"></a>2.5.3、后验</h6><p>有后验<br>$$\begin{align}<br>p \big(\bm{\eta}\mid \mathcal{D}\big)<br>= p \big(\bm{\eta}\mid \kappa_n,\bm{\tau}_n\big)<br>=p \big(\bm{\eta}\mid \kappa_0+n,\bm{\tau}_0+\bm{T}\big)<br>\end{align}$$</p>
<p>上式更新了超参。在规范形式下变成了<br>$$\begin{align}<br>p \big(\bm{\eta}\mid \mathcal{D}\big)<br>= p \big(\bm{\eta}\mid \kappa_n,\bar{\bm{\tau}}_n\big)<br>=p \big(\bm{\eta}\mid \kappa_0+n,\frac{ \kappa_0\bar{\bm{\tau}}_0+n\bar{\bm{T}}}{\kappa_0+n}\big)<br>\end{align}$$</p>
<p>因此我们看到后验超参是先验超参均值和充分统计量平均值一个凸组合。</p>
<h6 id="2-5-4、后验预测密度"><a href="#2-5-4、后验预测密度" class="headerlink" title="2.5.4、后验预测密度"></a>2.5.4、后验预测密度</h6><p>下面我们鉴于过去的数据集 $\displaystyle \mathcal{D}_t$，推导未来观测 $\displaystyle \mathcal{D}_{t+1}$的一个通用的预测密度的表达式。为简洁记，我们将把充分统计量与数据集大小写在一起： $\displaystyle \tilde{\bm{\tau}}_0=[\kappa_0;\bm{\tau}_0]$、 $\displaystyle \tilde{\bm{T}}_t=\big[n;\bm{T}\big(\mathcal{D}_t\big)\big]$、 $\displaystyle \tilde{\bm{T}}_{t+1}=\big[n;\bm{T}\big(\mathcal{D}_{t+1}\big)\big]$。先验、后验有：<br>$$\begin{align}<br>p \big(\bm{\eta}\mid \tilde{\bm{\tau}}_0\big)<br>=\frac{1}{Z( \tilde{\bm{\tau}}_0)}g^{\kappa_0}(\bm{\eta})\exp \big[\bm{\eta}^\text{T}(\bm{w})\bm{\tau}_0\big]<br>\end{align}$$</p>
<p>$$\begin{align}<br>p \big(\bm{\eta}\mid \mathcal{D}_t\big)<br>&amp;= \frac{p \big(\bm{\eta}\mid \tilde{\bm{\tau}}_0\big)p \big(\mathcal{D}_t\mid \bm{\eta}\big)}{p(\mathcal{D}_t)}<br>=p \big(\bm{\eta}\mid \tilde{\bm{\tau}}_0+\tilde{\bm{T}}_t\big)\\\\<br>&amp;=\frac{1}{Z( \tilde{\bm{\tau}}_0+\tilde{\bm{T}}_t)}g^{\kappa_0+n_t}(\bm{\eta})\exp \big[\bm{\eta}^\text{T}(\bm{w})\big[\bm{\tau}_0+\bm{T}_t\big]\big]<br>\end{align}$$</p>
<p> $\displaystyle  p \big(\mathcal{D}_{t+1}\mid \bm{\eta}\big)=\bigg[\prod_{i=1}^{n_{t+1}} h(\bm{x}_i)\bigg]g^{n_{t+1}}\big(\bm{\eta}\big)\exp \big[\bm{\eta}^\text{T}(\bm{w})\bm{T}_{t+1}\big]$那么后验预测为：$$\begin{align}<br>p \big(\mathcal{D}_{t+1}\mid \mathcal{D}_t\big)<br>&amp;=\int p \big(\mathcal{D}_{t+1}\mid \bm{\eta}\big)p \big(\bm{\eta}\mid \mathcal{D}_t\big)d \bm{\eta}\\\\<br>&amp;=\int\bigg[\prod_{i=1}^{n_{t+1}} h(\bm{x}_i)\bigg]g^{n_{t+1}}\big(\bm{\eta}\big)\exp \big[\bm{\eta}^\text{T}(\bm{w})\bm{T}_{t+1}\big]\frac{1}{Z( \tilde{\bm{\tau}}_0+\tilde{\bm{T}}_t)}g^{\kappa_0+n_t}(\bm{w})\exp \big[\bm{\eta}^\text{T}(\bm{w})\big[\bm{\tau}_0+\bm{T}_t\big]\big]d \bm{\eta}\\\\<br>&amp;=\bigg[\prod_{i=1}^{n_{t+1}} h(\bm{x}_i)\bigg] \frac{1}{Z( \tilde{\bm{\tau}}_0+\tilde{\bm{T}}_t)}\int g^{\kappa_0+n_t+n_{t+1}}\big(\bm{w}\big)\exp \big[\bm{\eta}^\text{T}(\bm{w})\big[\bm{\tau}_0+\bm{T}_t+\bm{T}_{t+1}\big]\big]d \bm{\eta}\\\\<br>&amp;=\bigg[\prod_{i=1}^{n_{t+1}} h(\bm{x}_i)\bigg] \frac{Z\big( \tilde{\bm{\tau}}_0+\tilde{\bm{T}}_t+\tilde{\bm{T}}_{t+1}\big)}{Z\big( \tilde{\bm{\tau}}_0+\tilde{\bm{T}}_t\big)}<br>\end{align}$$<br>的可能性和后部有一个类似的形式。因此如果 $\displaystyle n_t = 0$，这就变成了 $\displaystyle \mathcal{D}_{t+1}$的边际分布，这是我们熟悉后验的归一乘以一个常数。</p>
<h6 id="2-5-5、伯努利分布举例"><a href="#2-5-5、伯努利分布举例" class="headerlink" title="2.5.5、伯努利分布举例"></a>2.5.5、伯努利分布举例</h6><p>作为一个简单的例子，我们用新表示法来重新讨论一下：贝塔-伯努利模型。<br>似然函数是<br>$$\begin{align}<br>p \big(\mathcal{D}\mid \mu\big)=(1-\mu)^n\exp \bigg[\ln \bigg(\frac{\mu}{1-\mu}\bigg)\sum_{i=1}^n x_i\bigg]<br>\end{align}$$</p>
<p>共轭先验是：<br>$$\begin{align}<br>p \big(\mu\mid \kappa_0,\tau_0\big)<br>&amp;\propto (1-\mu)^{\kappa_0}\exp \bigg[\ln \bigg(\frac{\mu}{1-\mu}\bigg)\tau_0\bigg]=\mu^{\tau_0}\big(1-\mu\big)^{\kappa_0-\tau_0}<br>\end{align}$$</p>
<p>如果我们定义 $\displaystyle a_0=\tau_0+1$和 $\displaystyle b_0=\kappa_0-\tau_0+1$，我们可以看到这是一个贝塔分布。</p>
<p>我们可以推导出后验，其中 $\displaystyle T=\sum_{i=1}^n \mathbb{I}\big(x_i=1\big)$是充分统计量:<br>$$\begin{align}<br>p \big(\mu\mid \mathcal{D}\big)<br>&amp;\propto \mu^{\tau_0+T}\big(1-\mu\big)^{\kappa_0-\tau_0+n-T}\\\\<br>&amp;=\mu^{\tau_n}\big(1-\mu\big)^{\kappa_n-\tau_n}\\\\<br>&amp;=\mu^{a_n-1}\big(1-\mu\big)^{b_n-1}<br>\end{align}$$其中 $\displaystyle a_n=\tau_n+1$、 $\displaystyle b_n=\kappa_n-\tau_n+1$</p>
<p>我们可以推导出后验的预测分布。假设 $\displaystyle p (\mu)=\mathrm{Beta}\big(\mu\mid a_0,b_0\big)$，并让 $\displaystyle T_t=T(\mathcal{D}_t)$是硬币正面在过去的数量。我们可以预测给定一个未来序列 $\displaystyle \mathcal{D}_{t+1}$的出现正面的概率。令这个序列的充分统计量 $\displaystyle T_{t+1}=\sum_{i=1}^m \mathbb{I}\big(x_i^{t+1}=1\big)$<br>$$\begin{align}<br>p \big(\mathcal{D}_{t+1}\mid \mathcal{D}_t\big)<br>&amp;=\int_0^1 p \big(\mathcal{D}_{t+1}\mid \mu\big)p \big(\mu\mid \mathcal{D}_t\big)d\mu\\\\<br>&amp;=\int_0^1 p \big(\mathcal{D}_{t+1}\mid \mu\big)\mathrm{Beta} \big(\mu\mid a_{t},b_{t}\big)d\mu\\\\<br>&amp;=\frac{\Gamma(a_t+b_t)}{\Gamma{a_t}\Gamma(b_t)}\int_0^1 \mu^{a_t+T_{t+1}-1}\big(1-\mu\big)^{b_t+m-T_{t+1}-1}\\\\<br>&amp;=\frac{\Gamma(a_t+b_t)}{\Gamma{a_t}\Gamma(b_t)}\int_0^1 \mu^{a_{t+1}-1}\big(1-\mu\big)^{b_{t+1}-1}\\\\<br>&amp;=\frac{\Gamma(a_t+b_t)}{\Gamma(a_t)\Gamma(b_t)}<br>\frac{\Gamma(a_{t+1})\Gamma(b_{t+1})}{\Gamma(a_{t+1}+b_{t+1})}<br>\end{align}$$<br>其中<br>$\displaystyle a_{t+1}=a_t+T_{t+1}=\tau_0+T_t+1+T_{t+1}$<br>$\displaystyle b_{t+1}=\kappa_n-\tau_n+1=\kappa_0+n-(\tau_0+T_t)+1+m-T_{t+1}$</p>
<h5 id="2-6、指数族与最大熵原理-displaystyle-textit-Maximum-Entropy"><a href="#2-6、指数族与最大熵原理-displaystyle-textit-Maximum-Entropy" class="headerlink" title="2.6、指数族与最大熵原理 $\displaystyle \textit{(Maximum Entropy)} $"></a>2.6、指数族与最大熵原理 $\displaystyle \textit{(Maximum Entropy)} $</h5><p>虽然指数家族很方便，但对它的使用有更深层次的理由吗？事实存在这样的情况：如果用最少约束来假设数据，特别是假设某些特征或函数的期望<br>$$\begin{align}<br>\int \bm{\phi}(\bm{x})p(\bm{x})d \bm{x}=\mathrm{E}\big[\bm{\phi}\big]=\bm{\zeta}<br>\end{align}$$</p>
<p>$\displaystyle \bm{\zeta}\in \mathbb{R}^k$是已知常数向量， $\displaystyle \bm{\phi}(\bm{x})$是一个任意向量函数，即要求满足于分布矩与指定函数经验矩相匹配的约束条件，那么最大熵原理 $\displaystyle \textit{maxent} $告诉我们应该选择最大熵分布(最接近于均匀分布的那个)。有约束条件的熵最大化<br>$$\begin{align}<br>J(p)=&amp; \mathrm{H}[p]=-\int p (\bm{x})\ln p(\bm{x}) d \bm{x}\\\\<br>&amp;\mathrm{s.t.}<br>\begin{cases}<br>\displaystyle p(\bm{x})\geqslant 0\\\\<br>\displaystyle \int p(\bm{x})d \bm{x}= 1\\\\<br>\displaystyle \int \bm{\phi}(\bm{x})p(\bm{x})d \bm{x}=\bm{\zeta}<br>\end{cases}<br>\end{align}$$<br>我们需要使用拉格朗日乘数法，那么拉格朗日算符更新为：<br>$$\begin{align}<br>F(p)=-p (\bm{x})\ln p(\bm{x})+\lambda p(\bm{x})+\bm{\eta}^\text{T}\big[\bm{\phi}(\bm{x})p(\bm{x})\big]\\\\<br>\end{align}$$</p>
<p>我们可以用变分法计算函数 $\displaystyle p$，欧拉-拉格朗日方程是：<br>$$\begin{align}<br>-1-\ln p(\bm{x})+\lambda+\bm{\eta}^\text{T}\bm{\phi}(\bm{x})=0\iff p(\bm{x})=\exp[\lambda-1]\exp \big[\bm{\eta}^\text{T}\bm{\phi}(\bm{x})\big]<br>\end{align}$$<br>亦有 $\displaystyle p(\bm{x})\propto\exp \big[\bm{\eta}^\text{T}\bm{\phi}(\bm{x})\big]$、给出了归一化常数 $\displaystyle Z=\int \exp \big[\bm{\eta}^\text{T}\bm{\phi}(\bm{x})\big]d \bm{x}$ 有：<br>$$\begin{align}<br>p(\bm{x})=\frac{1}{Z}\exp \big[\bm{\eta}^\text{T}\bm{\phi}(\bm{x})\big]<br>\end{align}$$<br>因此，最大熵分布 $\displaystyle p(x)$具有指数族的形式，也称为吉布斯分布 $\displaystyle \textit{(Gibbs Distribution)} $。当然我们也可以写成离散形式，这是很容易的，略。</p>
<h4 id="三、广义线性模型-displaystyle-textit-GLMs"><a href="#三、广义线性模型-displaystyle-textit-GLMs" class="headerlink" title="三、广义线性模型$\displaystyle  \textit{(GLMs)} $"></a>三、广义线性模型$\displaystyle  \textit{(GLMs)} $</h4><h5 id="3-1、概要"><a href="#3-1、概要" class="headerlink" title="3.1、概要"></a>3.1、概要</h5><p>我们熟悉了一下指数族，建立广义模型的初衷是要解决，经典线性模型<br>$$\begin{align}<br>y=\bm{w}^\text{T}\bm{x}+e\sim\mathcal{N}(\mu,\sigma^2)<br>\end{align}$$的缺点：<br> 1、因变量 $\displaystyle y$是连续的且服从高斯分布。<br> 2、方差是固定的。</p>
<div align="center"><img src="/图片/广义线性模型.png" width="550"><br>广义线性模型</div>

<p>于是内尔得和韦德伯恩（Nelder &amp; Wedderburn，1972）提出了广义线性模型。我们对指数族的形式稍加修改。<br>$$\begin{align}<br>p\left(y\mid\eta,\delta\right)=\exp\left[\frac{y \cdot\eta-A(\eta)}{\delta}+c\left(y,\delta\right)\right]<br>\end{align}$$<br>其中 $\displaystyle \delta$是散度参数，通常是1、 $\displaystyle c\left(y,\delta\right)$是归一化参数、 $\displaystyle  A(\eta) $ 是分配函数、 $\displaystyle \eta$是连接函数，所谓规范连接函数可以查阅维基百科。同时我们令连接函数：<br>$\displaystyle g(\mu)=\eta=\bm{w}^\text{T}\bm{x}$</p>
<p>$\displaystyle \mu=\mathrm{E}\left[y\mid \bm{x}\right]=\dot{A}\left(\eta\right)=g^{-1}(\eta)$</p>
<p>$\displaystyle \mathrm{Var}\left[y\right]=\ddot{A}\left(\eta\right)\cdot\delta$<br>于是有$$\begin{align}<br>\left\{\begin{matrix}<br>g(\mu)=\eta=\bm{w}^\text{T}\bm{x}\\\\<br>e=y-\mu\\\\<br>e\sim f \end{matrix}\right.<br>\end{align}$$</p>
<p>再次写出模型：<br>$$\begin{align}<br>p \left(y\mid \bm{x} ,\bm{w} ,\delta\right)=\exp\left[\frac{ y\cdot\bm{w}^\text{T}\bm{x}-A(\bm{w}^\text{T}\bm{x})}{\delta}+c\left(y,\delta\right)\right]<br>\end{align}$$</p>
<p>经过以上分析,可以知道广义线性模型的两个重要不同：<br>1、连接函数：是因变量 $\displaystyle y$的期望的一个转换，此转换的变量 $\displaystyle g(\mu)$是回归参数 $\displaystyle \bm{w}$的一个线性函数 $\displaystyle \bm{x}^\text{T}\bm{w}$。</p>
<p>2、方差是因变量 $\displaystyle y$期望的函数： $\displaystyle\mathrm{Var}\left[y\right]=\ddot{A}\left(g(\mu)\right)\cdot\delta$</p>
<h5 id="3-2、对数似然函数"><a href="#3-2、对数似然函数" class="headerlink" title="3.2、对数似然函数"></a>3.2、对数似然函数</h5><p>广义线性模型有一个很吸引人的特性，即它可与逻辑斯蒂回归使用的方法相同。对于数据集 $\displaystyle \mathcal{D}=\{\bm{x}_i,y_i\}_{i=1}^{n}$我们有对数似然函数：</p>
<p>$$\begin{align}<br>\ell(\bm{w})<br>&amp;=\ln p \left(\mathcal{D}\mid \bm{w}\right)<br>=\frac{1}{\delta}\left[\bm{y}^\text{T}\bm{X}\bm{w}-\sum_{i-1}^{n}A(\bm{w}^\text{T}\bm{x}_i)\right]+\sum_{i=1}^{n}c\left(y_i,\delta\right)\\\\<br>&amp;=\frac{1}{\delta}\left[\bm{y}^\text{T}\bm{\eta}-\bm{I}^\text{T}A(\bm{\eta})\right]+\bm{I}^\text{T}c\left(\bm{y},\delta\right)<br>\end{align}$$</p>
<p>有梯度：<br>$$\begin{align}<br>&amp;\nabla\ell=\frac{\partial{\ell}}{\partial{\bm{w}}}<br>=\frac{1}{\delta}\left[\bm{X}^\text{T}\bm{y}-\sum_{i=1}^{n}A’\cdot \bm{x}_i\right]<br>=\frac{1}{\delta}\left[\bm{X}^\text{T}\bm{y}-\bm{X}^\text{T}\bm{\mu} \right]<br>=\frac{1}{\delta}\bm{X}^\text{T}\left[\bm{y}-\bm{\mu} \right]<br>\end{align}$$</p>
<p>有海赛矩阵：<br>$$\begin{align}<br>&amp;\bm{H}\left(\ell\right)<br>=\frac{\partial^2{\ell}}{\partial{\bm{w}\partial\bm{w}^\text{T}}}<br>=-\frac{1}{\delta}\bm{X}^\text{T}\frac{\partial{\bm{\mu}}}{\partial{\bm{\eta}^\text{T}}}\frac{\partial{\bm{\eta}}}{\partial{\bm{w}^\text{T}}}<br>=-\frac{1}{\delta}\bm{X}^\text{T}\bm{S}\bm{X}\\\\<br>\end{align}$$</p>
<p>其中：<br>$\displaystyle  \bm{S}=\frac{\partial{\bm{\mu}}}{\partial{\bm{\eta}^\text{T}}}=\mathrm{diag}\left[\frac{\partial \mu_i}{\partial\eta_i}\right]=\mathrm{diag}\left[\frac{\partial g^{-1}(\eta_i)}{\partial\eta_i}\right]$</p>
<p>$\displaystyle \frac{\partial{\bm{\eta}}}{\partial{\bm{w}^\text{T}}}=\frac{\partial \bm{X}\bm{w}}{\partial\bm{w}^\text{T}}=\bm{X} $</p>
<h5 id="3-3、牛顿-拉弗迭代法。"><a href="#3-3、牛顿-拉弗迭代法。" class="headerlink" title="3.3、牛顿-拉弗迭代法。"></a>3.3、牛顿-拉弗迭代法。</h5><p>为了求解模型，现在我们开考虑一下求极值问题,我们要求这样一个数量函数的极值：<br>$$\begin{align}<br>\max_{\bm{x}} f\left(\bm{x}\right)<br>\end{align}$$</p>
<p>我们有梯度： $\displaystyle \nabla f=\frac{\partial f}{\partial\bm{x}}=0$ 同时有海赛矩阵 $\displaystyle \bm{H}\left(f\right)=\frac{\partial f}{\partial\bm{x}\bm{x}^\text{T}}$。</p>
<p>于是我们有梯度的泰勒展开：<br>$$\begin{align}<br>\nabla\left(\bm{x}_t\right)=\nabla\left(\bm{x}_t\right)+\bm{H}\left(\bm{x}_t\right)\left[\bm{x}_{t+1}-\bm{x}_t\right]+\bm{r}\left(\bm{x}_t\right)=0<br>\end{align}$$</p>
<p>忽略余项，可以求得： $\displaystyle \bm{x}_{t+1}=\bm{x}_{t}-\bm{H}^{-1}\left(\bm{x}_t\right)\nabla \left(\bm{x}_t\right)$简写为：<br>$$\begin{align}<br>\bm{x}:=\bm{x}-\bm{H}^{-1}\nabla<br>\end{align}$$</p>
<p>$\displaystyle \\\\$</p>
<h5 id="3-4、极大似然分析"><a href="#3-4、极大似然分析" class="headerlink" title="3.4、极大似然分析"></a>3.4、极大似然分析</h5><p>$$\begin{align}<br>\bm{w}_{t+1}<br>&amp;=\bm{w}_t -\left[\bm{X}^\text{T}\bm{S}_t\bm{X}\right]^{-1}\bm{X}^\text{T}\left[\bm{y}-\bm{\mu}_t\right]\\\\<br>&amp;=\left[\bm{X}^\text{T}\bm{S}_t\bm{X}\right]^{-1}\left[\bm{X}^\text{T}\bm{S}_t\bm{X}\bm{w}_t-\bm{X}^\text{T}\left[\bm{y}-\bm{\mu}_t\right]\right]\\\\<br>&amp;=\left[\bm{X}^\text{T}\bm{S}_t\bm{X}\right]^{-1}\bm{X}^\text{T}\bm{S}_t\left[\bm{\eta}_t-\bm{S}_t^{-1}\left[\bm{y}-\bm{\mu}_t\right]\right]\\\\<br>&amp;=\left[\bm{X}^\text{T}\bm{S}_t\bm{X}\right]^{-1}\bm{X}^\text{T}\bm{S}_t\bm{\zeta}_t<br>\end{align}$$<br><!-- 作者：引线小白
邮箱：limoncc@icloud.com
网址：www.limoncc.com  --><br>其中：<br>$\displaystyle \bm{\eta}_t=\bm{X}\bm{w}_t$<br>$\displaystyle \bm{\mu}_t=g^{-1}\left(\bm{\eta}_t\right)$<br>$\displaystyle \bm{S}_t<br>=\frac{\partial\bm{\mu}_t}{\partial\bm{\eta}_t^\text{T}}<br>=\mathrm{diag}\left[\frac{\partial g^{-1}(\eta_i^t)}{\partial\eta_i^t}\right]$<br>$\displaystyle \bm{\zeta}_t=\bm{\eta}_t-\bm{S}_t^{-1}\left[\bm{y}-\bm{\mu}_t\right]$</p>
<p>现在我们加以总结，历史上我们称这种算法为：迭代加权最小二乘法（IRLS）</p>
<hr>
<p>算法：迭代加权最小二乘法（Iteratively reweighted least squares）</p>

<hr>
<p><font face="Times" new="" roman="" size="3" color="#0066CC">1 $\displaystyle \bm{w}_0=g(\bar{y})$<br>2 $\displaystyle \text{while }\bm{w}=\text{converged}$ :<br> $\displaystyle<br>\quad\begin{array}{|lc}<br>\bm{\eta}_t=\bm{X}\bm{w}_t\\\\\displaystyle<br>\bm{\mu}_t=g^{-1}\left(\bm{\eta}_t\right)\\\\\displaystyle<br>\bm{S}_t=\frac{\partial\bm{\mu}_t}{\partial\bm{\eta}_t^\text{T}}\\\\\displaystyle<br>\bm{\zeta}_t=\bm{\eta}_t-\bm{S}_t^{-1}\left[\bm{y}-\bm{\mu}_t\right]\\\\\displaystyle<br>\bm{w}_{t+1}=\left[\bm{X}^\text{T}\bm{S}_t\bm{X}\right]^{-1}\bm{X}^\text{T}\bm{S}_t\bm{\zeta}_t<br>\end{array}\\\\<br>$<br>3 #end while</font></p>
<hr style="height:1px;border:none;border-top:1px dashed #0066CC;">

<p>如果我们扩展这个推导来处理非规范连接函数，我们就会发现海赛矩阵有另一个术语。然而结果表明海赛矩阵期望与公式相同；使用海赛矩阵期望(称为 $\displaystyle \textit{Fisher} $信息矩阵)来替代实际的海赛矩阵，称为 $\displaystyle \textit{Fisher}$评分方法。</p>
<p>在此基础上，我们可以简单地将上述过程修改为高斯先验的 $\displaystyle \textit{MAP} $估计，即我们只需修改目标、梯度和海赛矩阵，就像我们对逻辑斯蒂回归增加 $\displaystyle \ell_2$正则一样。</p>
<h5 id="4、评述"><a href="#4、评述" class="headerlink" title="4、评述"></a>4、评述</h5><p>使用广义线性模型我们解决了指数族分布的通用贝叶斯模型。这里我们跳过了多元高斯分布的模型。这涉及到高维，和多元统计的wishart分布。需要更为高级的工具：</p>
<p>1、格拉斯曼代数<br>2、微分形式<br>3、外微分</p>
<p>稍后，我们将一一提及它们。继续我们的星辰大海。</p>
<p><hr></p>
<p><table border="1" width="100%"><tr><td align="center" width="18%">版权声明</td><td align="left" width="82%"><img src="http://www.limoncc.com/images/cc.png" width="18%"></td></tr><tr><td align="center" width="18%"><img src="http://www.limoncc.com/images/avatar.png" width="100%"></td><td align="left" width="82%">由<a href="http://www.limoncc.com">引线小白</a>创作并维护的<a href="http://www.limoncc.com">柠檬CC</a>博客采用<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="external">署名-非商业-禁止演绎4.0</a>国际许可证。<br>本文首发于柠檬CC <a href="http://www.limoncc.com">[ http://www.limoncc.com ]</a> , 版权所有、侵权必究。</td></tr><tr><td align="center" width="18%">本文永久链接</td><td align="left" width="82%"><a href="http://www.limoncc.com/机器学习/2017-03-09-广义线性模型/">http://www.limoncc.com/机器学习/2017-03-09-广义线性模型/</a></td></tr></table><div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a><a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a><a href="#" class="bds_duitang" data-cmd="duitang" title="分享到堆糖"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a><a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a></div></p>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{},"image":{"viewList":["tsina","douban","weixin","sqq","duitang","qzone","fbook","twi"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","douban","weixin","sqq","duitang","qzone","fbook","twi"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag">#机器学习</a>
          
            <a href="/tags/广义线性模型/" rel="tag">#广义线性模型</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/机器学习/2017-03-08-狄利克雷-多项式模型/" rel="next" title="狄利克雷-多项式模型(Dirichlet-Multionmial Model)">
                <i class="fa fa-chevron-left"></i> 狄利克雷-多项式模型(Dirichlet-Multionmial Model)
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/机器学习/2017-03-10-概率图基础/" rel="prev" title="概率图基础">
                概率图基础 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


<!--           </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div> -->
        <div id="vcomments"></div>
        <script>new Valine({
          el: "#vcomments",
      appId: "BVjuNRCpkVSkz82jFmadIvY8-gzGzoHsz",
    appKey: "bRjXPp55dop7RTC2xgunGdiP"})
  </script>'
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="引线小白" />
          <p class="site-author-name" itemprop="name">引线小白</p>
          <p class="site-description motion-element" itemprop="description">小湖椰影廊桥,曾记否,谷围晓月,灯影朦胧。</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">25</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">43</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="" target="_blank" title="Design">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Design
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="https://www.behance.net/limoncc" target="_blank" title="Behance">
                  
                    <i class="fa fa-fw fa-behance"></i>
                  
                  Behance
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="https://www.pinterest.com/aegeanfan/" target="_blank" title="Pinterest">
                  
                    <i class="fa fa-fw fa-pinterest"></i>
                  
                  Pinterest
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="https://github.com/limoncc" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="http://weibo.com/3483157951" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="http://www.zhihu.com/people/limoncc" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              设计不止，折腾不息。
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://chuangzaoshi.com" title="创造狮" target="_blank">创造狮</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#一、-简述"><span class="nav-number">1.</span> <span class="nav-text">一、 简述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#二、-指数族"><span class="nav-number">2.</span> <span class="nav-text">二、 指数族</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1、定义"><span class="nav-number">2.1.</span> <span class="nav-text">2.1、定义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2、对数配分函数"><span class="nav-number">2.2.</span> <span class="nav-text">2.2、对数配分函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3、例子"><span class="nav-number">2.3.</span> <span class="nav-text">2.3、例子</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#2-3-1、-displaystyle-textit-0-1-分布"><span class="nav-number">2.3.1.</span> <span class="nav-text">2.3.1、 $\displaystyle \textit{0-1}$分布</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-3-2-、分类分布"><span class="nav-number">2.3.2.</span> <span class="nav-text">2.3.2 、分类分布</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-3-3、单变量高斯"><span class="nav-number">2.3.3.</span> <span class="nav-text">2.3.3、单变量高斯</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-2-4、非例子"><span class="nav-number">2.3.4.</span> <span class="nav-text">2.2.4、非例子</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4、指数族的-displaystyle-textit-MLE"><span class="nav-number">2.4.</span> <span class="nav-text">2.4、指数族的 $\displaystyle  \textit{MLE}$</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-5、指数族的贝叶斯"><span class="nav-number">2.5.</span> <span class="nav-text">2.5、指数族的贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#2-5-1、似然函数"><span class="nav-number">2.5.1.</span> <span class="nav-text">2.5.1、似然函数</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-5-2、先验"><span class="nav-number">2.5.2.</span> <span class="nav-text">2.5.2、先验</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-5-3、后验"><span class="nav-number">2.5.3.</span> <span class="nav-text">2.5.3、后验</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-5-4、后验预测密度"><span class="nav-number">2.5.4.</span> <span class="nav-text">2.5.4、后验预测密度</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-5-5、伯努利分布举例"><span class="nav-number">2.5.5.</span> <span class="nav-text">2.5.5、伯努利分布举例</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-6、指数族与最大熵原理-displaystyle-textit-Maximum-Entropy"><span class="nav-number">2.6.</span> <span class="nav-text">2.6、指数族与最大熵原理 $\displaystyle \textit{(Maximum Entropy)} $</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#三、广义线性模型-displaystyle-textit-GLMs"><span class="nav-number">3.</span> <span class="nav-text">三、广义线性模型$\displaystyle  \textit{(GLMs)} $</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1、概要"><span class="nav-number">3.1.</span> <span class="nav-text">3.1、概要</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2、对数似然函数"><span class="nav-number">3.2.</span> <span class="nav-text">3.2、对数似然函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-3、牛顿-拉弗迭代法。"><span class="nav-number">3.3.</span> <span class="nav-text">3.3、牛顿-拉弗迭代法。</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-4、极大似然分析"><span class="nav-number">3.4.</span> <span class="nav-text">3.4、极大似然分析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4、评述"><span class="nav-number">3.5.</span> <span class="nav-text">4、评述</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">引线小白&nbsp &nbsp |&nbsp &nbsp  一个理想主义者，再造自我，以期未来。</span>
</div>

<div class="powered-by">
  由 <a rel="external nofollow" class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a rel="external nofollow" class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>&nbsp &nbsp| &nbsp &nbsp Hosted by  <a href="https://github.com" style="font-weight: bold">Github Pages</a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



<!--   
   
  

  

 -->
  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').mousedown(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
     showMathMenu: false,
     showMathMenuMSIE: false,
     tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
          processEscapes: true
        },
        TeX: {
          equationNumbers: {autoNumber: 'AMS'},
          Macros: {bm: "\\boldsymbol"}
        },
        'HTML-CSS': {
          imageFont: null
        }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("Es7wAnqi0QiGhMLoyl7mkrQo-gzGzoHsz", "BxPXaoPFp3PzWqBTSe6VUuQS");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

</body>
</html>
