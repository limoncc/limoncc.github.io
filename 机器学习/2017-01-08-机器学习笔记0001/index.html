<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,笔记,引线小白,机器学习框架" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="机器学习框架, 当我们理解了：输入空间、输出空间、算法空间、假设空间、参数空间后，我们就能建立起机器学习的基本框架。从而加深理解。本文同时还解释了梯度下降算法、和正则方程的几何意义。">
<meta name="keywords" content="机器学习,笔记,引线小白,机器学习框架">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习概论">
<meta property="og:url" content="http://www.limoncc.com/机器学习/2017-01-08-机器学习笔记0001/index.html">
<meta property="og:site_name" content="柠檬CC">
<meta property="og:description" content="机器学习框架, 当我们理解了：输入空间、输出空间、算法空间、假设空间、参数空间后，我们就能建立起机器学习的基本框架。从而加深理解。本文同时还解释了梯度下降算法、和正则方程的几何意义。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://www.limoncc.com/图片/机器学习框架.png">
<meta property="og:image" content="http://www.limoncc.com/图片/相图.png">
<meta property="og:image" content="http://www.limoncc.com/图片/相图2.png">
<meta property="og:image" content="http://www.limoncc.com/图片/线性回归.jpg">
<meta property="og:image" content="http://www.limoncc.com/images/cc.png">
<meta property="og:image" content="http://www.limoncc.com/images/avatar.png">
<meta property="og:updated_time" content="2019-12-25T15:09:23.509Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习概论">
<meta name="twitter:description" content="机器学习框架, 当我们理解了：输入空间、输出空间、算法空间、假设空间、参数空间后，我们就能建立起机器学习的基本框架。从而加深理解。本文同时还解释了梯度下降算法、和正则方程的几何意义。">
<meta name="twitter:image" content="http://www.limoncc.com/图片/机器学习框架.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: undefined,
      author: '博主'
    }
  };
</script>

  <title> 机器学习概论 | 柠檬CC </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-73837972-3', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?d225b8f8559eb2eb6a8bd8792e01ebb9";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  <script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=60130136";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">柠檬CC</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">小白爱吃柠檬O(∩_∩)O</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-poetry">
          <a href="/poetry" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-leaf"></i> <br />
            
            诗集
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                机器学习概论
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-01-08T15:34:53+08:00" content="2017-01-08">
              2017-01-08
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/机器学习/2017-01-08-机器学习笔记0001/" class="leancloud_visitors" data-flag-title="机器学习概论">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>作者: <a href="http://www.limoncc.com">引线小白</a>-本文永久链接：<a href="http://www.limoncc.com/机器学习/2017-01-08-机器学习笔记0001/">http://www.limoncc.com/机器学习/2017-01-08-机器学习笔记0001/</a><br>知识共享许可协议: 本博客采用<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="external">署名-非商业-禁止演绎4.0</a>国际许可证</p>
<h3 id="一、机器学习若干符号解释"><a href="#一、机器学习若干符号解释" class="headerlink" title="一、机器学习若干符号解释"></a>一、机器学习若干符号解释</h3><p>我们在表达概念时，通常用集合论，空间之类的术。这个时候，我们注意元素和集合的区别。而在我们表达运算时，我们通常用矩阵的概念，这个时候你要注意维度、列、行的概念。多加练习，你很快就会掌握这个表达。</p>
<h4 id="1、输入空间"><a href="#1、输入空间" class="headerlink" title="1、输入空间"></a>1、输入空间</h4><p>用矩阵表示数据集$\mathcal{D} : \boldsymbol{X}=\left[\begin{array}{c}\boldsymbol{x}_{1}^\text{T}\\\boldsymbol{x}_{2}^\text{T}\\\vdots\\\boldsymbol{x}_{n}^\text{T}\end{array}\right]=\left[\begin{array}{c}\boldsymbol{x}_{1,:}^\text{T}\\\boldsymbol{x}_{2,:}^\text{T}\\\vdots\\\boldsymbol{x}_{n,:}^\text{T}\end{array}\right]=\left[\begin{array}{ccc}x_{1,1} &amp; \dots &amp; x_{1,k} \\\vdots &amp; \dots &amp; \vdots \\x_{n,1} &amp; \dots &amp; x_{n,k}\end{array}\right]$。$\displaystyle  \boldsymbol{x}_i=\boldsymbol{x}_{i,:} $表示用 $\displaystyle \boldsymbol{X} $的第i行转置构造向量 $\displaystyle \underbrace {\boldsymbol{x}_i}_{k\times1} $<br>用matlab举个例子：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%矩阵与机器学习</span></span><br><span class="line">&gt;&gt; X=[<span class="number">12</span>, <span class="number">14</span>, <span class="number">15</span>; <span class="number">1.5</span>, <span class="number">5.4</span> ,<span class="number">6.7</span>;<span class="number">20</span>,<span class="number">3.4</span>,<span class="number">5</span>]</span><br><span class="line">X =</span><br><span class="line">   <span class="number">12.0000</span>   <span class="number">14.0000</span>   <span class="number">15.0000</span></span><br><span class="line">    <span class="number">1.5000</span>    <span class="number">5.4000</span>    <span class="number">6.7000</span></span><br><span class="line">   <span class="number">20.0000</span>    <span class="number">3.4000</span>    <span class="number">5.0000</span></span><br><span class="line">&gt;&gt; x1=X(<span class="number">1</span>,:)'</span><br><span class="line">x1 =</span><br><span class="line">    <span class="number">12</span></span><br><span class="line">    <span class="number">14</span></span><br><span class="line">    <span class="number">15</span></span><br><span class="line">&gt;&gt; x1(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">ans</span> =</span><br><span class="line">    <span class="number">14</span></span><br></pre></td></tr></table></figure>
<p>所以 $\displaystyle \boldsymbol{x_1} $表示包含k个维度的一次观测(示例)。我们用集合论的方式再叙述一遍有n个样本的数据集或者样本空间 $\displaystyle X=\{\boldsymbol{x}_1,\,\boldsymbol{x}_2,\, …,\,\boldsymbol{x}_i,\,…,\,\boldsymbol{x}_n\} \subseteq \mathcal{X}^n$ ,其中 $\displaystyle \boldsymbol{x}_i $是样本点(样本)，我们把输入的所有可能取值集合 $\displaystyle \mathcal{X} $叫做输入空间,无监督学习下也可以称为样本空间。显然 $\displaystyle X\subseteq\mathcal{X}^n $。</p>
<p>输入空间的矩阵表示和集合表示我们需要多加熟悉、灵活运用。这是我们思考多维问题的基础。</p>
<h4 id="2、输出空间"><a href="#2、输出空间" class="headerlink" title="2、输出空间"></a>2、输出空间</h4><p>集合$\displaystyle Y=\{y_1\,,y_2\,,..\,,y_i\,,…\,,y_n\} \subseteq \mathcal{Y} $，其中输出空间 $\displaystyle \mathcal{Y} $、 输入样本$\displaystyle Y $、输入样本点 $\displaystyle y_i $。</p>
<p>矩阵表示： $\displaystyle \boldsymbol{y}=[y_1\,,y_2\,,..\,,y_i\,,…\,,y_n]^{\text{T}} $</p>
<p>在有监督学习中，我们把集合 $\displaystyle \{(\boldsymbol{x}_i,y_i)\mid 1 \leqslant i\leqslant n\}$也叫做训练集$\mathcal{D}$ ，$\displaystyle (\boldsymbol{x}_i,y_i) $表示第i个样本。</p>
<p>符号$\displaystyle P(y\mid \boldsymbol{x})=\mathcal{N}(y\mid \boldsymbol{x}^{\text{T}}\boldsymbol{\beta},\sigma)$与$\displaystyle y\mid \boldsymbol{x}\sim\mathcal{N}( \boldsymbol{x}^{\text{T}}\boldsymbol{\beta},\sigma)$是同一个意思。注意 $\displaystyle \mid $的不同意思。[^1]</p>
<p>统计学中，我们写成这样 $\displaystyle P(y\mid\boldsymbol{x},\boldsymbol{\beta}) $和 $\displaystyle P(\boldsymbol{x}\mid\boldsymbol{\beta}) $</p>
<p>机器学习中，我们写成这样 $\displaystyle P(y\mid\boldsymbol{x},\boldsymbol{w}) $和 $\displaystyle P(\boldsymbol{x}\mid\boldsymbol{w}) $</p>
<h4 id="3、假设空间："><a href="#3、假设空间：" class="headerlink" title="3、假设空间："></a>3、假设空间：</h4><h5 id="1、如果真实的世界的关系是-displaystyle-y-h-boldsymbol-x-，-世界充满噪声。所以-displaystyle-y-h-boldsymbol-x-e-。"><a href="#1、如果真实的世界的关系是-displaystyle-y-h-boldsymbol-x-，-世界充满噪声。所以-displaystyle-y-h-boldsymbol-x-e-。" class="headerlink" title="1、如果真实的世界的关系是 $\displaystyle y=h(\boldsymbol{x})$， 世界充满噪声。所以 $\displaystyle y=h(\boldsymbol{x})+e$。"></a>1、如果真实的世界的关系是 $\displaystyle y=h(\boldsymbol{x})$， 世界充满噪声。所以 $\displaystyle y=h(\boldsymbol{x})+e$。</h5><p>现在我们有一个样本或者数据集 $\displaystyle \mathcal{D}=\{(\boldsymbol{x}_i,y_i)\}_{i=1}^{n}$。我们想通过这个数据集 $\displaystyle \mathcal{D}$估计出 $\displaystyle f(\boldsymbol{x})$来找到 $\displaystyle h(\boldsymbol{x})$。其实我们能找到的 $\displaystyle f$有很多，现在我们把它汇集起来： $\displaystyle \mathcal{H}=\{f_i\}$。我们的模型是 $\displaystyle y=f(\boldsymbol{x})+\varepsilon$。</p>
<p>现在我们换一个说法:<br>1、世界是这样的： $\displaystyle p(y=h(\boldsymbol{x})\mid\boldsymbol{x})$<br>2、我们观察到的世界是这样的：$\displaystyle \mathcal{D}=\{(\boldsymbol{x}_i,y_i)\}_{i=1}^{n}$<br>3、我们假设世界是这样的： $\displaystyle p(y=f(\boldsymbol{x)\mid }\boldsymbol{x},\mathcal{D},M)$[^1]，其中 $\displaystyle M$是模型(算法)。<br>于是<br>$\displaystyle \varepsilon=y-f=y-h+h-f=y-h+h-\mathrm{E}[f]+\mathrm{E}[f]-f$<br>$\displaystyle \mathrm{E}[\varepsilon^2]=\mathrm{Var}[e]+\left(h-\mathrm{E}[f]\right)^2+\mathrm{E}\left[\left(f-\mathrm{E}[f]\right)^2\right]$<br>$$ 平方损失期望=噪声方差+偏误^2+模型方差$$</p>
<p>4、我们还可以写成：<br>$\displaystyle \mathcal{H} =\{f\mid p(y=f(\boldsymbol{x})\mid\boldsymbol{x}, \mathcal{D})\}=\{f(\boldsymbol{\beta})\mid p(y=f(\boldsymbol{x};\boldsymbol{\beta})\mid \boldsymbol{x},\mathcal{D};\boldsymbol{\beta}),\boldsymbol{\beta}\in \mathbb{R}^k\}$。这里的$\displaystyle \mathcal{H} $是模型 $f$的集合。</p>
<h5 id="2、这里的符号有一个重要的解释："><a href="#2、这里的符号有一个重要的解释：" class="headerlink" title="2、这里的符号有一个重要的解释："></a>2、这里的符号有一个重要的解释：</h5><p>$\displaystyle y $是一个随机变量，它的取值是 $\displaystyle y=y_i $。 $\displaystyle \boldsymbol{x} $表示的是 $\displaystyle n $个 $\displaystyle k $维输入数据。也就是说 $\displaystyle \boldsymbol{x} $也是一个变量，不过是向量的形式。它的取值是 $\displaystyle \boldsymbol{x}=\boldsymbol{x}_i $。</p>
<h5 id="3、换一个程序员比较好理解的说法："><a href="#3、换一个程序员比较好理解的说法：" class="headerlink" title="3、换一个程序员比较好理解的说法："></a>3、换一个程序员比较好理解的说法：</h5><p>$\displaystyle y,\boldsymbol{x} $是一个类。而 $\displaystyle y_i,\boldsymbol{x}_i $是一个实例。所以一个实例 $\displaystyle  P(y_i\mid \boldsymbol{x}_i,\mathcal{D})$，又有 $\displaystyle  P(y_{n+1}\mid \boldsymbol{x}_{n+1},\mathcal{D})$是一个数或者一个概率。$\displaystyle \hat{y},\hat{y}_i $也是类和实例的区别。 </p>
<!-- 然而当我们把$\displaystyle y_i $不做为一个数看待时，它也是一个随机变量。$\displaystyle  P(y_i\mid \boldsymbol{x},\mathcal{D})$ -->
<p>输出的最佳估计： $\displaystyle \hat{y}=\hat{f}(x)=\mathop {\text{argmax}}\limits_{\hat{y}}P(y=\hat{y}\mid \boldsymbol{x},\mathcal{D})$</p>
<h4 id="4、算法空间"><a href="#4、算法空间" class="headerlink" title="4、算法空间"></a>4、算法空间</h4><p>$\displaystyle \zeta\in\mathcal{L} $，它是算法的集合。</p>
<h4 id="5、参数空间"><a href="#5、参数空间" class="headerlink" title="5、参数空间"></a>5、参数空间</h4><p>$\displaystyle \boldsymbol{\beta} \in\mathbb{R}^k $。这里的元素我们将 $\displaystyle \mathbb{R}^k$的k维有序组与向量矩阵$\mathop{\boldsymbol{\beta}}\limits_{(k\times 1)}$等同，以方便表达。</p>
<h4 id="6、概念总结"><a href="#6、概念总结" class="headerlink" title="6、概念总结"></a>6、概念总结</h4><p>有了这些基本概念，我们就可以建立起机器学习的基本框架。一张图搞定:</p>
<div align="center"><img src="http://www.limoncc.com/图片/机器学习框架.png" alt="机器学习框架" width="35%"><br>机器学习框架</div>

<h4 id="7、指示函数，或者叫示性函数"><a href="#7、指示函数，或者叫示性函数" class="headerlink" title="7、指示函数，或者叫示性函数"></a>7、指示函数，或者叫示性函数</h4><p>$\displaystyle \mathrm{I}_x(A)=\begin{cases}1&amp;\text{if }x\in A\\0&amp;\text{if }x\notin A\end{cases}$</p>
<h4 id="8、评论"><a href="#8、评论" class="headerlink" title="8、评论"></a>8、评论</h4><p>这段概论，大部分是站在频率学派的角度解释的，以后我们还会用贝叶斯学派的观点。</p>
<p>我们注意到符号与文字的转换要非常熟练，这就像英语，如果做到同声翻译的水平，这将有利于快速理解。所以一套好的数学符号是非常关键，<strong>好数学符号令人赏心悦目</strong>。但是每个人都有不同的风格，这就有点无语，以至于不同的书，符号不一样。TMD这是英语有了方言啊。有些书上的符号真是丑的不堪入目啊。严重影响阅读学习体验。</p>
<hr>
<h3 id="二、回归模型"><a href="#二、回归模型" class="headerlink" title="二、回归模型"></a>二、回归模型</h3><h4 id="1、线性回归模型："><a href="#1、线性回归模型：" class="headerlink" title="1、线性回归模型："></a>1、线性回归模型：</h4><p>模型的一些表示方法<br>$ y_i=\boldsymbol{x}_{i}^T\boldsymbol{\beta}+\epsilon_i=\boldsymbol{x}_{i,:\,}^T\boldsymbol{\beta}+\epsilon_i$<br>$\boldsymbol{y}=\boldsymbol{X}\boldsymbol{\beta}+\boldsymbol{\epsilon}$<br>$S=\boldsymbol{\epsilon}^{\text{T}}\boldsymbol{\epsilon} $<br>模型矩阵解释：<br>$$\displaystyle  \mathop{\boldsymbol{y}}\limits_{(n\times 1)}=\underbrace{\mathop{\boldsymbol{X}}\limits_{(n\times k)} \mathop{\boldsymbol{\beta}}\limits_{(k\times 1)}}_{n\times k} +\mathop{\boldsymbol{\epsilon}}\limits_{(n\times 1)} $$</p>
<h4 id="2、梯度下降算法：-boldsymbol-beta-boldsymbol-beta-alpha-nabla-S"><a href="#2、梯度下降算法：-boldsymbol-beta-boldsymbol-beta-alpha-nabla-S" class="headerlink" title="2、梯度下降算法：$\boldsymbol{\beta}: =\boldsymbol{\beta}-\alpha\nabla S$"></a>2、梯度下降算法：$\boldsymbol{\beta}: =\boldsymbol{\beta}-\alpha\nabla S$</h4><p>梯度下降算法的本质：可以使用相图的思想加以理解。例如有关系$\displaystyle F(x,y,t)=0$。如果我们画出<br>$$<br>\begin{cases}<br>\dot{x}=-3x+5y\\<br>\dot{y}=-5x-7\sin(y)<br>\end{cases}<br>$$动力系统的相图。那么如果是凸函数。相图上的曲线集就会流向平衡点。如图</p>
<div align="center"><img src="http://www.limoncc.com/图片/相图.png" alt="相图" width="50%"><br>相图</div><br>所谓梯度就是图中的箭头乘以梯度的大小。代表了该点速度最快的方向。而 $\displaystyle\alpha_k$就是给梯度加了一个控制器。<br>所以应该能够理解梯度下降算法了：$$\boldsymbol{\beta}_{k+1}=\boldsymbol{\beta}_{k}-\alpha_k\nabla S(\boldsymbol{\beta}_k)$$所以当系统比较复杂的时候，必然就面临问题。例如这种：<br>$$<br>\begin{cases}<br>\dot{x}=-x+y\\<br>\dot{y}=xy-1<br>\end{cases}<br>$$这个系统就非常复杂了。初始位置不同，我们将走向完全不同的结局。<br><div align="center"><img src="http://www.limoncc.com/图片/相图2.png" alt="相图2" width="50%"><br>相图2</div>

<h5 id="3、规范方程"><a href="#3、规范方程" class="headerlink" title="3、规范方程"></a>3、规范方程</h5><p>规范方程的本质可以如下理解：</p>
<div align="center"><img src="http://www.limoncc.com/图片/线性回归.jpg" alt="线性回归几何解释" width="100%"><br>线性回归几何解释</div>

<p>解决学习平方误差 $\displaystyle  S$的最小化问题：<br>$$\mathop {\min }\limits_\boldsymbol{\beta}S=\boldsymbol{\epsilon}^{\text{T}}\boldsymbol{\epsilon}  $$简单推理易得：$\hat{\boldsymbol{\beta}}=(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}$</p>
<p>现在我们用线性空间的概念来加以理解：<br>$\displaystyle  \boldsymbol{X}$张成的空间,或者说超平面 $\displaystyle span(\boldsymbol{X})=span(\boldsymbol{x}_{:,1},…,\boldsymbol{x}_{:,j},…,\boldsymbol{x}_{:,k})$ 这里的 $\displaystyle\boldsymbol{x}_{:,j}=\left[\begin{array}{c}x_{1,j} \\x_{2,j}\\\vdots\\x_{n,j}\end{array}\right]$。如图我们很容发现要使得 $\displaystyle\boldsymbol{\epsilon} $的欧式距离最短。那么$\displaystyle\boldsymbol{\epsilon} $必然与 $\displaystyle span(\boldsymbol{x}_{:,1},…,\boldsymbol{x}_{:,jj},…,\boldsymbol{x}_{:,k})$垂直。即有如下方程。<br>$$\boldsymbol{X}^T\boldsymbol{\epsilon}=\boldsymbol{X}^T(\boldsymbol{y}-\boldsymbol{X}\hat{\boldsymbol{\beta}})=\boldsymbol{0}$$简单推理易得：$\hat{\boldsymbol{\beta}}=(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}$。所以 $\displaystyle \boldsymbol{y} $的最佳估计量 $\displaystyle \hat{\boldsymbol{y} }$是 $\displaystyle \boldsymbol{y} $在$\displaystyle span(\boldsymbol{x}_{:,1},…,\boldsymbol{x}_{:,jj},…,\boldsymbol{x}_{:,k})$空间上的投影。</p>
<hr>
<h3 id="注释："><a href="#注释：" class="headerlink" title="注释："></a>注释：</h3><p>[^1]: 如果 $\displaystyle \zeta$表示算法,可写为$\displaystyle P(y\mid \boldsymbol{x},\mathcal{D},\zeta) $</p>
<p><hr></p>
<p><table border="1" width="100%"><tr><td align="center" width="18%">版权声明</td><td align="left" width="82%"><img src="http://www.limoncc.com/images/cc.png" width="18%"></td></tr><tr><td align="center" width="18%"><img src="http://www.limoncc.com/images/avatar.png" width="100%"></td><td align="left" width="82%">由<a href="http://www.limoncc.com">引线小白</a>创作并维护的<a href="http://www.limoncc.com">柠檬CC</a>博客采用<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="external">署名-非商业-禁止演绎4.0</a>国际许可证。<br>本文首发于柠檬CC <a href="http://www.limoncc.com">[ http://www.limoncc.com ]</a> , 版权所有、侵权必究。</td></tr><tr><td align="center" width="18%">本文永久链接</td><td align="left" width="82%"><a href="http://www.limoncc.com/机器学习/2017-01-08-机器学习笔记0001/">http://www.limoncc.com/机器学习/2017-01-08-机器学习笔记0001/</a></td></tr></table><div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a><a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a><a href="#" class="bds_duitang" data-cmd="duitang" title="分享到堆糖"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a><a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a></div></p>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{},"image":{"viewList":["tsina","douban","weixin","sqq","duitang","qzone","fbook","twi"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","douban","weixin","sqq","duitang","qzone","fbook","twi"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>
      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag">#机器学习</a>
          
            <a href="/tags/人工智能/" rel="tag">#人工智能</a>
          
            <a href="/tags/大数据分析/" rel="tag">#大数据分析</a>
          
            <a href="/tags/神经网络/" rel="tag">#神经网络</a>
          
            <a href="/tags/大数据/" rel="tag">#大数据</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/统计学/2017-01-08-三大分布/" rel="next" title="三大分布">
                <i class="fa fa-chevron-left"></i> 三大分布
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/概率论/2017-01-09-多元高斯分布/" rel="prev" title="多元高斯分布">
                多元高斯分布 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="引线小白" />
          <p class="site-author-name" itemprop="name">引线小白</p>
          <p class="site-description motion-element" itemprop="description">小湖椰影廊桥,曾记否,谷围晓月,灯影朦胧。</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">23</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">43</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="" target="_blank" title="Design">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Design
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="https://www.behance.net/limoncc" target="_blank" title="Behance">
                  
                    <i class="fa fa-fw fa-behance"></i>
                  
                  Behance
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="https://www.pinterest.com/aegeanfan/" target="_blank" title="Pinterest">
                  
                    <i class="fa fa-fw fa-pinterest"></i>
                  
                  Pinterest
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="https://github.com/limoncc" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="http://weibo.com/3483157951" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a rel="external nofollow" href="http://www.zhihu.com/people/limoncc" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              设计不止，折腾不息。
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://chuangzaoshi.com" title="创造狮" target="_blank">创造狮</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#一、机器学习若干符号解释"><span class="nav-number">1.</span> <span class="nav-text">一、机器学习若干符号解释</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1、输入空间"><span class="nav-number">1.1.</span> <span class="nav-text">1、输入空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2、输出空间"><span class="nav-number">1.2.</span> <span class="nav-text">2、输出空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3、假设空间："><span class="nav-number">1.3.</span> <span class="nav-text">3、假设空间：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1、如果真实的世界的关系是-displaystyle-y-h-boldsymbol-x-，-世界充满噪声。所以-displaystyle-y-h-boldsymbol-x-e-。"><span class="nav-number">1.3.1.</span> <span class="nav-text">1、如果真实的世界的关系是 $\displaystyle y=h(\boldsymbol{x})$， 世界充满噪声。所以 $\displaystyle y=h(\boldsymbol{x})+e$。</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2、这里的符号有一个重要的解释："><span class="nav-number">1.3.2.</span> <span class="nav-text">2、这里的符号有一个重要的解释：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3、换一个程序员比较好理解的说法："><span class="nav-number">1.3.3.</span> <span class="nav-text">3、换一个程序员比较好理解的说法：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4、算法空间"><span class="nav-number">1.4.</span> <span class="nav-text">4、算法空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5、参数空间"><span class="nav-number">1.5.</span> <span class="nav-text">5、参数空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6、概念总结"><span class="nav-number">1.6.</span> <span class="nav-text">6、概念总结</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7、指示函数，或者叫示性函数"><span class="nav-number">1.7.</span> <span class="nav-text">7、指示函数，或者叫示性函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8、评论"><span class="nav-number">1.8.</span> <span class="nav-text">8、评论</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二、回归模型"><span class="nav-number">2.</span> <span class="nav-text">二、回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1、线性回归模型："><span class="nav-number">2.1.</span> <span class="nav-text">1、线性回归模型：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2、梯度下降算法：-boldsymbol-beta-boldsymbol-beta-alpha-nabla-S"><span class="nav-number">2.2.</span> <span class="nav-text">2、梯度下降算法：$\boldsymbol{\beta}: =\boldsymbol{\beta}-\alpha\nabla S$</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3、规范方程"><span class="nav-number">2.2.1.</span> <span class="nav-text">3、规范方程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#注释："><span class="nav-number">3.</span> <span class="nav-text">注释：</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">引线小白</span>
</div>

<div class="powered-by">
  由 <a rel="external nofollow" class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a rel="external nofollow" class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>&nbsp &nbsp| &nbsp &nbsp Hosted by <a href="https://coding.net" style="font-weight: bold">Coding Pages</a> and <a href="https://github.com" style="font-weight: bold">Github Pages</a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  
   
  

  


  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').mousedown(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
     showMathMenu: false,
     showMathMenuMSIE: false,
     tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
          processEscapes: true
        },
        TeX: {
          equationNumbers: {autoNumber: 'AMS'},
          Macros: {bm: "\\boldsymbol"}
        },
        'HTML-CSS': {
          imageFont: null
        }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("Es7wAnqi0QiGhMLoyl7mkrQo-gzGzoHsz", "BxPXaoPFp3PzWqBTSe6VUuQS");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

</body>
</html>
